{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../resources/cropped-SummerWorkshop_Header.png\">  \n",
    "\n",
    "<h1 align=\"center\">Brain Observatory - Neuropixels </h1> \n",
    "<h2 align=\"center\">Summer Workshop on the Dynamic Brain </h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<p>This notebook will introduce you to the Neuropixel dataset and SDK functions. \n",
    "<p>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# tab completion in the notebook sometimes has trouble with large dataframes\n",
    "# this will fix it\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "platstring = platform.platform()\n",
    "\n",
    "if 'Darwin' in platstring:\n",
    "    # OS X \n",
    "    data_root = \"/Volumes/Brain2021/\"\n",
    "elif 'Windows'  in platstring:\n",
    "    # Windows (replace with the drive letter of USB drive)\n",
    "    data_root = \"E:/\"\n",
    "elif ('amzn1' in platstring):\n",
    "    # then on AWS\n",
    "    data_root = \"/data/allen-brain-observatory/visual-coding-neuropixels\"\n",
    "else:\n",
    "    # then your own linux platform\n",
    "    # EDIT location where you mounted hard drive\n",
    "    data_root = \"/media/$USERNAME/Brain2021/\"\n",
    "\n",
    "manifest_path = os.path.join(data_root, \"ecephys-cache/manifest.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>The main entry point is the `EcephysProjectCache` class.  This class is responsible for downloading any requested data or metadata as needed and storing it in well known locations.  For this workshop, all of the data has been preloaded onto the hard drives you have received, and is available on AWS.\n",
    "\n",
    "<p>We begin by importing the `EcephysProjectCache` class and instantiating it.\n",
    "\n",
    "<p>`manifest_path` is a path to the manifest file.  We will use the manifest file preloaded onto your Workshop hard drives.  Make sure that `drive_path` is set correctly for your platform.  (See the first cell in this notebook.)\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache\n",
    "from allensdk.brain_observatory.ecephys import ecephys_session\n",
    "\n",
    "cache = EcephysProjectCache(manifest=manifest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cache.get_all_session_types())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    <h2>1. Exploring available sessions of the dataset</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 1:</b>  Get information about what's in the Neuropixel dataset from the `cache` object we created above.\n",
    "\n",
    "<p>Use the `get_session_table()` function to retrieve a dataframe of all the available sessions. What information does this dataframe contain?\n",
    "\n",
    "- How many sessions are there in the dataset?\n",
    "- What is the average number of units in an experiment? The max number? The minimum?\n",
    "- What are the different genotypes that were used in these experiments? How many sessions per genotype?\n",
    "- What are all the brain structures that data has been collected from?\n",
    "- How many sessions have data from VISp?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = cache.get_session_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many sessions are available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the average number of units in a session? The max? The min?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the different genotypes that were used for this dataset? How many sessions per genotype are available?\n",
    "\n",
    "Note: genotypes are described in the <a href=\"http://help.brain-map.org/download/attachments/10616846/VisualCoding_TransgenicCharacterization.pdf?version=4&modificationDate=1538067045225&api=v2\">Transgenic Line Catalog</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the different session types? How many sessions per type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are all the structures that data has been collected from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get more information about these structures, visit [our reference atlas web app](http://atlas.brain-map.org/atlas?atlas=602630314)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many sessions have data from VISp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>The session object</h2>\n",
    "<p>The session object contains all the data and metadata for a single experiment session, including spike times, stimulus information, unit waveforms and derived metrics, LFP, and the mouse's running speed. \n",
    "\n",
    "<p>Session objects are accessed using <b>cache.get_session_data(session_id)</b>\n",
    "\n",
    "<p><b>Note:</b> experiment data is loaded upon initialization of the class. Some data can be accessed directly as an attribute of the class, others by using 'get' functions. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select one session to examine in detail. First we'll narrow down the list of sessions to those that are 'brain_observatory_1.1' type sessions with > 500 units and wildtype genotype: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sessions[\n",
    "    (sessions['unit_count'] > 500) & \n",
    "    (sessions['session_type'] == 'brain_observatory_1.1') &\n",
    "    (sessions['full_genotype'] == 'wt/wt')\n",
    "].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pick one of these sessions at random to examine in greater detail. \n",
    "session_id = 750749662"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use `cache.get_session_data` to get the EcephysSession object for this session. This object contains the data that is stored in the NWB file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = cache.get_session_data(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session objects have several attributes that describe data acquired during the session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps the most important of these attributes is `session.units`, which is a dataframe describing all units that were isolated in the session and that passed the QC metric filters implemented in `cache.get_session_data`. "
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h2> 2. Unit properties</h2>\n",
    "\n",
    "<p> The primary data in this dataset is the recorded activity of isolated units. A number of metrics are used to isolate units through spike sorting, and these metrics can be used to access how well isolated they are and the quality of each unit. The `session.units` dataframe provides many of these metrics, as well as parameterization of the waveform for each unit that passed initial QC, including\n",
    "</p>\n",
    "<ul>\n",
    "<li> <b>firing rate:</b> mean spike rate during the entire session\n",
    "<li> <b>presence ratio:</b> fraction of session when spikes are present\n",
    "<li> <b>ISI violations:</b> rate of refractory period violations\n",
    "<li> <b>Isolation distances:</b> distance to nearest cluster in Mihalanobis space\n",
    "<li> <b>d':</b> classification accuracy based on LDA\n",
    "<li> <b>SNR:</b> signal to noise ratio\n",
    "<li> <b>Maximum drift:</b> Maximum change in spike depth during recording\n",
    "<li> <b>Cumulative drift:</b> Cumulative change in spike depth during recording\n",
    "</ul>\n",
    "\n",
    "<b>1D Waveform features:</b>\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "<b>Note:</b> By default, `cache.get_session_data` returns data only for units that are considered to be 'valid' based on their QC metrics. For more information, see:\n",
    "\n",
    "<ul>\n",
    "<li><a href=\"https://allensdk.readthedocs.io/en/latest/visual_coding_neuropixels.html#quality-metrics\">https://allensdk.readthedocs.io/en/latest/visual_coding_neuropixels.html#quality-metrics</a>\n",
    "<li><a href=\"https://github.com/AllenInstitute/ecephys_spike_sorting/tree/master/ecephys_spike_sorting/modules/quality_metrics\">https://github.com/AllenInstitute/ecephys_spike_sorting/tree/master/ecephys_spike_sorting/modules/quality_metrics</a>\n",
    "<li><a href=\"https://github.com/AllenInstitute/ecephys_spike_sorting/tree/master/ecephys_spike_sorting/modules/mean_waveforms\">https://github.com/AllenInstitute/ecephys_spike_sorting/tree/master/ecephys_spike_sorting/modules/mean_waveforms</a>\n",
    "</ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 2: Units</b>  \n",
    "\n",
    "<p> Get the `units` dataframe for this session. \n",
    "\n",
    "What metrics are described in this data? (i.e. what are the columns for the dataframe?)\n",
    "\n",
    "How many units are there? How many units per structure?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "session.units.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many units are in this session?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which areas (structures) are they from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many units per area are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    \n",
    "<h3>The <i>firing_rate</i> column contains the average firing rate for each unit.</h3>\n",
    "\n",
    "Let's make a violinplot of the overall firing rates of units across structures:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group all firing rates by structure name\n",
    "grouped = session.units.groupby('ecephys_structure_acronym')['firing_rate'].apply(list).to_dict()\n",
    "\n",
    "plt.violinplot(grouped.values(), range(len(grouped.keys())))\n",
    "plt.xticks(range(len(grouped.keys())), grouped.keys())\n",
    "plt.ylabel('firing rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    \n",
    "<h3>The <i>probe_vertical_position</i> column contains the position of each unit along its probe.</h3>\n",
    "\n",
    "Let's plot the location of all units on one probe from this session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "# restrict to one probe\n",
    "probe_id = session.units.probe_id.values[0]\n",
    "probe_units = session.units[session.units.probe_id==probe_id]\n",
    "\n",
    "# group and color the data by structure\n",
    "for structure in probe_units['ecephys_structure_acronym'].unique():\n",
    "    structure_mask = probe_units['ecephys_structure_acronym'] == structure\n",
    "    plt.hist(probe_units[structure_mask]['probe_vertical_position'].values, \n",
    "             bins=100, range=(0,3200), label=structure)\n",
    "plt.legend()\n",
    "plt.xlabel('Probe vertical position (Î¼m)', fontsize=16)\n",
    "plt.ylabel('Unit count', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    \n",
    "<h3>Unit receptive field metrics</h3>\n",
    "\n",
    "<p> Neurons in the visual cortex respond most strongly to a particular region in space, known as the receptive field. The receptive fields of neurons in this dataset have already been computed. Let's see what part of the monitor the units in this experiment preferred.\n",
    "    \n",
    "There are a few relevant parameters: the elevation_rf, azimuth_rf, area_rf, and p_value_rf\n",
    "\n",
    "<p>For more information, see:</p>\n",
    "<p><ul>\n",
    "<li><a href=\"https://allensdk.readthedocs.io/en/latest/_static/examples/nb/ecephys_receptive_fields.html\">https://allensdk.readthedocs.io/en/latest/_static/examples/nb/ecephys_receptive_fields.html</a>\n",
    "</ul></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select units that have a significant receptive field. How many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_units = session.units[session.units['p_value_rf'] < 0.01]\n",
    "len(rf_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where on the screen were the receptive fields of these units?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "#restrict to units with a significant receptive field\n",
    "#color points by probe ID\n",
    "plt.scatter(\n",
    "    x=rf_units['azimuth_rf'],\n",
    "    y=rf_units['elevation_rf'],\n",
    "    c=rf_units['probe_id'],\n",
    ")\n",
    "plt.ylabel('elevation')\n",
    "plt.xlabel('azimuth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big were the receptive fields?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "#restrict to units with a significant receptive field\n",
    "#add receptive field size to the plot\n",
    "plt.scatter(\n",
    "    x=rf_units['azimuth_rf'],\n",
    "    y=rf_units['elevation_rf'],\n",
    "    s=rf_units['area_rf'],\n",
    "    c=rf_units['probe_id'],\n",
    "    alpha=0.4\n",
    ")\n",
    "plt.ylabel('elevation')\n",
    "plt.xlabel('azimuth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h2> Spike Times</h2>\n",
    "\n",
    "<p> The primary data in this dataset is the recorded acrtivity of isolated units. The attribute `session.spike_times` is a dictionary of spike times for each units in the session.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 3: Spike Times</b>\n",
    "\n",
    "<p> Next let's find the `spike_times` for these units. What type of object is `session.spike_times`? How many items does it include? What are the keys and values?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What type of object is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(session.spike_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many items does it include?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the keys for this object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These keys are unit ids. Use the unit_id for the first unit to get the spike times for that unit. How many spikes does it have in the entire session?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h3>Plotting spike times</h3>\n",
    "    \n",
    "<p>Let's first select all units in primary visual cortex (VISp) and generate raster plots of spike times as well as binned spike counts.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all units in VISp \n",
    "visp_units = session.units[session.units['ecephys_structure_acronym'] == 'VISp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a random unit:\n",
    "unit_id = visp_units.index[10]\n",
    "\n",
    "# make a raster plot of its spike times\n",
    "spikes = session.spike_times[unit_id]\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(spikes, np.zeros(len(spikes)), '|')\n",
    "plt.xlabel(\"Time (s)\")\n",
    "\n",
    "# limit to just the first 300 seconds\n",
    "plt.xlim(0, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 5px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    \n",
    "A raster plot may not work for visualizing the activity across the entire session as there are too many spikes! An alternative is to plot the activity in 1 second bins:\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_spikes, bin_edges = np.histogram(spikes, bins=np.arange(0, max(spikes)))\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(bin_edges[:-1], binned_spikes)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"FR (Hz)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 5px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<p> Now let's do this for up to 50 units in V1. We'll make an array of the binned activity of all units in V1 called 'visp_binned'. We'll use this again later.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate an empty array to hold binned spike rates for up to 50 units\n",
    "numunits = min(50, len(visp_units))\n",
    "numbins = len(binned_spikes)\n",
    "visp_binned = np.empty((numunits, numbins))\n",
    "\n",
    "# compute binned spike rates for each unit:\n",
    "for i in range(numunits):\n",
    "    unit_id = visp_units.index[i]\n",
    "    spikes = session.spike_times[unit_id]\n",
    "    visp_binned[i] = np.histogram(spikes, bins=bin_edges)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the activity of all the units, one above the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "for i in range(numunits):\n",
    "    plt.plot(bin_edges[:-1], i + (visp_binned[i,:] / 30.), color='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h2> 3. Stimulus presentations</h2>\n",
    "\n",
    "<p> A variety of visual stimuli were presented throughout the recording session, and the session object contains detailed information about what stimuli were presented when.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of all stimuli that were used in the session:\n",
    "session.stimulus_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    \n",
    "<h3>Stimulus epochs</h3>\n",
    "\n",
    "<p> These stimuli are interleaved throughout the session. We can use `session.get_stimulus_epochs()` to see when each stimulus type was presented. Then we'll add this to the activity plot we made above.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_epochs = session.get_stimulus_epochs()\n",
    "stimulus_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 5px; padding-left: 10px; background: #F0FAFF; \">\n",
    "Let's replot our V1 activity from above, shading each stimulus epoch with a unique color using <b>plt.axvspan()</b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "for i in range(numunits):\n",
    "    plt.plot(bin_edges[:-1], i + (visp_binned[i,:] / 30.), color='gray')\n",
    "\n",
    "colors = ['blue','orange','green','red','yellow','purple','magenta','gray','lightblue']\n",
    "for c, stim_name in enumerate(session.stimulus_names):\n",
    "    stim = stimulus_epochs[stimulus_epochs.stimulus_name==stim_name]\n",
    "    for j in range(len(stim)):\n",
    "        plt.axvspan(\n",
    "            xmin=stim[\"start_time\"].iloc[j], \n",
    "            xmax=stim[\"stop_time\"].iloc[j], \n",
    "            color=colors[c], \n",
    "            alpha=0.1\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 4:</b> Get the running speed\n",
    "\n",
    "<p> Before we dig further into the stimulus information in more detail, let's add one more piece of session-wide data to our plot: the mouse's running speed.  \n",
    "\n",
    "Use `session.running_speed` to plot the running speed as a function of time. You may need to do some introspection here--what type of object is running_speed? How can you access both the running speed and time values?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 5px; padding-left: 10px; background: #F0FAFF; \">\n",
    "Let's add the running speed to the plot of V1 activity and stimulus epochs.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.ylim(-20,52)\n",
    "\n",
    "# plot binned spike rates\n",
    "for i in range(numunits):\n",
    "    plt.plot(bin_edges[:-1], i + (visp_binned[i, :] / 30.), color='gray')\n",
    "\n",
    "# plot running speed, with scale/offset to place it below spike plots\n",
    "plt.plot(session.running_speed['end_time'], (0.3 * session.running_speed['velocity']) - 20)\n",
    "\n",
    "# color session regions\n",
    "colors = ['blue','orange','green','red','yellow','purple','magenta','gray','lightblue']\n",
    "for c, stim_name in enumerate(session.stimulus_names):\n",
    "    stim = stimulus_epochs[stimulus_epochs.stimulus_name==stim_name]\n",
    "    for j in range(len(stim)):\n",
    "        plt.axvspan(\n",
    "            xmin=stim[\"start_time\"].iloc[j], \n",
    "            xmax=stim[\"stop_time\"].iloc[j], \n",
    "            color=colors[c], \n",
    "            alpha=0.1\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 5px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    \n",
    "<h3>Pupil data</h3>\n",
    "    \n",
    "<p> Let's also add one more piece of data that is highly correlated with running and arousal: the pupil data.  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pupil_data = session.get_pupil_data()\n",
    "pupil_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 5px; padding-left: 10px; background: #F0FAFF; \">\n",
    "There are many variables here but for now let's focus on the pupil diameter/width, which is closely related with the animal's level of arousal.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pupil diameter alongside running speed\n",
    "fig, ax = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "ax[0].plot(pupil_data.index, pupil_data['pupil_width'])\n",
    "ax[0].set_ylabel(\"Pupil width\")\n",
    "ax[0].set_ylim(0, 100)\n",
    "\n",
    "ax[1].plot(session.running_speed['end_time'], session.running_speed['velocity'])\n",
    "ax[1].set_xlabel(\"Time (s)\")\n",
    "ax[1].set_ylabel(\"Running speed\")\n",
    "ax[1].set_ylim(0, 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 5px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h3>Stimulus presentations</h3>\n",
    "\n",
    "<p> Now let's go back and learn more about the stimulus that was presented. The session object has a function that returns a table for a given stimulus called `get_stimulus_table`.\n",
    "    \n",
    "In some cases, you might instead want the information for all types of stimulus in one table - this is stored in 'session.stimulus_presentations', although it takes a while to load.\n",
    "\n",
    "Use this to get the stimulus table for drifting gratings and for natural scenes. What information do these tables provide? How are they different?\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_table = session.get_stimulus_table('drifting_gratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the stimulus table for natural scenes. What is different about these tables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_table_ns = session.get_stimulus_table('natural_scenes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_table_ns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
    "<b>Drifting gratings stimulus parameters</b>\n",
    "\n",
    "<p> Use the drifting grating stimulus table to determine what are the unique parameters for the different stimulus conditions of this stimulus.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_table.orientation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_table.spatial_frequency.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_table.temporal_frequency.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_table.contrast.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think the 'null' conditions are?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
    "<b>Natural scenes image presentations</b>\n",
    "\n",
    "<p> Use the stimulus table for natural scenes to find all the times when a particular image is presented during the session, and add it to the plot of activity in V1.  Pick the first image that was presented in this session.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_table_ns[stim_table_ns.frame==stim_table_ns.frame.iloc[0]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many times was it presented?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stim_table_ns[stim_table_ns.frame==stim_table_ns.frame.iloc[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mark the times when this particular scene was presented on our plot of the activity (without the epochs and running speed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for i in range(numunits):\n",
    "    plt.plot(i+(visp_binned[i,:]/30.), color='gray')\n",
    "    \n",
    "stim_subset = stim_table_ns[stim_table_ns.frame==stim_table_ns.frame.iloc[0]]\n",
    "for j in range(len(stim_subset)):\n",
    "    plt.axvspan(xmin=stim_subset.start_time.iloc[j], xmax=stim_subset.stop_time.iloc[j], color='r', alpha=0.5)\n",
    "plt.xlim(5000,9000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
    "<b>Natural scene stimulus template</b> \n",
    "\n",
    "<p> What is this image? The `stimulus template` provides the images and movies that were presented to the mouse. These are only provided for stimuli that are images (natural scenes, natural movies) - parametric stimuli (eg. gratings) do not have templates.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_num = 60\n",
    "image_template = cache.get_natural_scene_template(image_num)\n",
    "\n",
    "plt.imshow(image_template, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
    "    <b>Single trial raster plots for all units.</b>\n",
    "\n",
    "<p>Now that we've seen the pieces of data, we can explore the neural activity in greater detail. Make a raster plot for a single presentation of the drifting grating stimulus at orientation=45 degrees and temporal frequency = 2 Hz.\n",
    "\n",
    "To start, make a function to make a raster plot of all the units in the experiment.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raster(spike_times, start, end):\n",
    "    num_units = len(spike_times)\n",
    "    ystep = 1 / num_units\n",
    "\n",
    "    ymin = 0\n",
    "    ymax = ystep\n",
    "\n",
    "    for unit_id, unit_spike_times in spike_times.items():\n",
    "        unit_spike_times = unit_spike_times[np.logical_and(unit_spike_times >= start, unit_spike_times < end)]\n",
    "        plt.vlines(unit_spike_times, ymin=ymin, ymax=ymax)\n",
    "\n",
    "        ymin += ystep\n",
    "        ymax += ystep\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the first presentation of our chosen grating condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_table = session.get_stimulus_table('drifting_gratings')\n",
    "subset = stim_table[(stim_table.orientation==45)&(stim_table.temporal_frequency==2)]\n",
    "start = stim_table.start_time.iloc[0]\n",
    "end = stim_table.stop_time.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the plot_raster function to plot the response of all units to this trial. Pad the raster plot with half a second before and after the trial, and shade the trial red (with an alpha of 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plot_raster(session.spike_times, start-0.5, end+0.5)\n",
    "plt.axvspan(start, end, color='red', alpha=0.1)\n",
    "plt.xlabel('Time (sec)', fontsize=16)\n",
    "plt.ylabel('Units', fontsize=16)\n",
    "plt.tick_params(axis=\"y\", labelleft=False, left=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "<p>Use the `unit` dataframe to arrange the neurons in the raster plot according to their overall firing rate. \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "session.units.sort_values(by=\"firing_rate\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(session.units.sort_values(by=\"firing_rate\", ascending=False).firing_rate.values, 'o')\n",
    "plt.ylabel(\"Firing rate (Hz)\")\n",
    "plt.xlabel(\"Unit #\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_fr = session.units.sort_values(by=\"firing_rate\", ascending=False)\n",
    "spike_times_by_firing_rate = {\n",
    "    uid: session.spike_times[uid] for uid in by_fr.index.values\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plot_raster(spike_times_by_firing_rate, start-0.5, end+0.5)\n",
    "plt.axvspan(start, end, color='red', alpha=0.1)\n",
    "plt.ylabel('Units', fontsize=16)\n",
    "plt.xlabel('Time (sec)', fontsize=16)\n",
    "plt.tick_params(axis=\"y\", labelleft=False, left=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h2>4. Stimulus responses</h2>\n",
    "\n",
    "<p> A lot of the analysis of these data will requires comparing responses of neurons to different stimulus conditions and presentations. The SDK has functions to help access these, sorting the spike data into responses for each stimulus presentations and converting from spike times to binned spike counts. This spike histogram representation is more useful for many computations, since it can be treated as a timeseries and directly averaged across presentations. \n",
    "\n",
    "<p>The `presentationwise_spike_counts` provides the histograms for specified stimulus presentation trials for specified units. The function requires <b>stimulus_presentation_ids</b> for the stimulus in question, <b>unit_ids</b> for the relevant units, and <b>bin_edges</b> to specify the time bins to count spikes in (relative to stimulus onset).\n",
    "\n",
    "<p>The `conditionwise_spike_statistics` creates a summary of specified units responses to specified stimulus conditions, including the mean spike count, standard deviation, and standard error of the mean.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 5: Presentation-wise analysis for drifting gratings</b>\n",
    "\n",
    "<p>  \n",
    "\n",
    "Pick  a specific condition of the drifting grating stimulus and create spike histograms for the units in V1.\n",
    "<p>Create bins at a 10 ms resolution so we can see dynamics on a fast timescale.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the time bins in seconds, relative to stimulus onset\n",
    "time_step = 1/100.\n",
    "duration = stim_table.duration.iloc[0]\n",
    "time_domain = np.arange(0, duration+time_step, time_step)\n",
    "print(time_domain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_ids = stim_table[(stim_table.orientation==90)&(stim_table.temporal_frequency==1)].index\n",
    "print(stim_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms = session.presentationwise_spike_counts(bin_edges=time_domain, \n",
    "                                                   stimulus_presentation_ids=stim_ids, \n",
    "                                                   unit_ids=visp_units.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What type of object is this? What is its shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h3>Xarray</h3>\n",
    "\n",
    "This has returned a new (to this notebook) data structure, the `xarray.DataArray`. You can think of this as similar to a 3+D `pandas.DataFrame`, or as a `numpy.ndarray` with labeled axes and indices. See the [xarray documentation](http://xarray.pydata.org/en/stable/index.html) for more information. In the mean time, the salient features are:\n",
    "\n",
    "- Dimensions : Each axis on each data variable is associated with a named dimension. This lets us see unambiguously what the axes of our array mean.\n",
    "- Coordinates : Arrays of labels for each sample on each dimension.\n",
    "\n",
    "xarray is nice because it forces code to be explicit about dimensions and coordinates, improving readability and avoiding bugs. However, you can always convert to numpy or pandas data structures as follows:\n",
    "\n",
    "- to pandas: `histograms.to_dataframe()` produces a multiindexed dataframe\n",
    "- to numpy: `histograms.values` gives you access to the underlying numpy array\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
    "<p>Plot the response of the first unit to all 15 trials\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    plt.plot(histograms.time_relative_to_stimulus_onset, i+histograms[i,:,0])\n",
    "plt.xlabel(\"Time (s)\", fontsize=16)\n",
    "plt.ylabel(\"Trials\", fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
    "<p>Compute the mean of the trials for all units, and plot a heatmap of mean response for all units in V1\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_histograms = histograms.mean(dim=\"stimulus_presentation_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_histograms.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray.plot as xrplot\n",
    "xrplot.imshow(darray=mean_histograms, x=\"time_relative_to_stimulus_onset\",\n",
    "                                      y=\"unit_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
    "<h3>Conditionwise analysis</h3> \n",
    "\n",
    "In order to compute a tuning curve that summarizes the responses of a unit to each stimulus condition of a stimulus, use the `conditionwise_spike_statistics` to summarize the activity of specific units to the different stimulus conditions.\n",
    "\n",
    "<p> \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_ids = stim_table.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_stats = session.conditionwise_spike_statistics(stimulus_presentation_ids=stim_ids, unit_ids=visp_units.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What type of object is this? What is its shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dg_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_stats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are its columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_stats.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you explain the first dimension?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Merge the conditionwise statistics with stimulus information</b>\n",
    "\n",
    "In order to link the stimulus responses with the stimulus conditions, merge the spike_statistics output with the stimulus table using `pd.merge()`.\n",
    "\n",
    "<p> \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_stats_stim = pd.merge(dg_stats, session.stimulus_conditions, on='stimulus_condition_id', right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "This dataframe currently has a *multi-index*, meaning that each row is indexed by the pair of unit_id and stimulus_condition_id, rather than a single identifier. There are several ways to use this index:\n",
    "\n",
    "- specify the pair of identifiers as a tuple: `dg_stats_stim.loc[(unit_id, stim_id)]`\n",
    "- specifying the axis makes it easier to get all rows for one unit: `dg_stats_stim.loc(axis=0)[unit_id, :]`\n",
    "- or you can use `dg_stats_stim.reset_index()` to move the index to regular columns\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_stats_stim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
    "<p>Plot a 2D tuning curve for the first unit, comparing responses across temporal frequency and orientation.\n",
    "\n",
    "\n",
    "<p> \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_id = visp_units.index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_ids = stim_table.index.values\n",
    "session.get_stimulus_parameter_values(stimulus_presentation_ids=stim_ids, drop_nulls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "orivals = session.get_stimulus_parameter_values(stimulus_presentation_ids=stim_ids, drop_nulls=True)['orientation']\n",
    "tfvals = session.get_stimulus_parameter_values(stimulus_presentation_ids=stim_ids, drop_nulls=True)['temporal_frequency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_mean = np.empty((len(orivals), len(tfvals)))\n",
    "response_sem = np.empty((len(orivals), len(tfvals)))\n",
    "for i,ori in enumerate(orivals):\n",
    "    for j,tf in enumerate(tfvals):\n",
    "        stim_id = stim_table[(stim_table.orientation==ori)&(stim_table.temporal_frequency==tf)].stimulus_condition_id.iloc[0]\n",
    "        response_mean[i,j] = dg_stats_stim.loc[(unit_id, stim_id)].spike_mean\n",
    "        response_sem[i,j] = dg_stats_stim.loc[(unit_id, stim_id)].spike_sem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(response_mean)\n",
    "plt.xlabel(\"Temporal frequency (Hz)\")\n",
    "plt.ylabel(\"Direction (deg)\")\n",
    "plt.xticks(range(5), tfvals)\n",
    "plt.yticks(range(8), orivals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h2>5. Unit waveforms</h2>\n",
    "\n",
    "<p> For each unit, the average action potential waveform has been recorded from each channel of the probe. This is contained in the `mean_waveforms` object. This is the characteristic pattern that distinguishes each unit in spike sorting, and it can also help inform us regarding differences between cell types. \n",
    "\n",
    "<p>We will use this in conjuction with the `channel_structure_intervals` function which tells us where each channel is located in the brain. This will let us get a feel for the spatial extent of the extracellular action potential waveforms in relation to specific structures.\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "Get the waveform for one unit.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = session.mean_waveforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What type of object is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(waveforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the keys?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(waveforms.keys())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the waveform for one unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = session.units.index.values[400]\n",
    "wf = session.mean_waveforms[unit]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What type of object is this? What is its shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wf, aspect=0.2, origin='lower')\n",
    "plt.xlabel('Time steps')\n",
    "plt.ylabel('Channel #')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Unit waveform channel locations</b> \n",
    "\n",
    "<p> \n",
    "Use the `channel_structure_intervals` to get information about where each channel is located.\n",
    "\n",
    "We need to pass this function a list of channel ids, and it will identify channels that mark boundaries between identified brain regions. \n",
    "\n",
    "<p>We can use this information to add some context to our visualization.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass in the list of channels from the waveforms data\n",
    "structure_acronyms, intervals = session.channel_structure_intervals(wf.channel_id.values)\n",
    "print(structure_acronyms)\n",
    "print(intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place tick marks at the interval boundaries, and labels at the interval midpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.imshow(wf, aspect=0.2, origin='lower')\n",
    "plt.colorbar(ax=ax)\n",
    "\n",
    "ax.set_xlabel(\"time (s)\")\n",
    "ax.set_yticks(intervals)\n",
    "# construct a list of midpoints by averaging adjacent endpoints\n",
    "interval_midpoints = [ (aa + bb) / 2 for aa, bb in zip(intervals[:-1], intervals[1:])]\n",
    "ax.set_yticks(interval_midpoints, minor=True)\n",
    "ax.set_yticklabels(structure_acronyms, minor=True)\n",
    "plt.tick_params(\"y\", which=\"major\", labelleft=False, length=40)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if this matches the structure information saved in the units table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.units.loc[unit, \"ecephys_structure_acronym\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
    "    <p><b>Plot the mean waveform for the peak channel for each unit in the dentate gyrus (DG) </b>\n",
    "\n",
    "<p> Start by plotting the mean waveform for the peak channel for the unit we just looked at. \n",
    "Then do this for all the units in DG, making a heatmap of these waveforms\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the peak channel for this unit, and plot the mean waveform for just that channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_id = session.units.loc[unit, 'peak_channel_id']\n",
    "print(channel_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wf.loc[{\"channel_id\": channel_id}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "th_unit_ids = session.units[session.units.ecephys_structure_acronym==\"DG\"].index.values\n",
    "\n",
    "peak_waveforms = []\n",
    "\n",
    "for unit_id in th_unit_ids:\n",
    "\n",
    "    peak_ch = session.units.loc[unit_id, \"peak_channel_id\"]\n",
    "    unit_mean_waveforms = session.mean_waveforms[unit_id]\n",
    "\n",
    "    peak_waveforms.append(unit_mean_waveforms.loc[{\"channel_id\": peak_ch}])\n",
    "    \n",
    "    \n",
    "time_domain = unit_mean_waveforms[\"time\"]\n",
    "\n",
    "peak_waveforms = np.array(peak_waveforms)\n",
    "plt.pcolormesh(peak_waveforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h2> 6. Local Field Potential (LFP)</h2>\n",
    "<p>\n",
    "The final aspect of a Neuropixels probe recording we will investigate is the local field potential (LFP). An LFP signal is a direct recordings of extracellular voltage from which individual spike contributions have been removed by low-pass filtering. The remaining signal reflects the population activity of a large number of cells in the vicinity of the probe, primarily through the electrical field effects of synaptic currents (along with other trans-membrane currents).\n",
    "</p>\n",
    "<p>\n",
    "LFP can be especially informative for understanding rhythmic activity or oscillations in neural circuits, which can be identified by some simple time-series analysis of the LFP signals.\n",
    "</p>\n",
    "<p>\n",
    "For more information, see: \n",
    "</p>\n",
    "<ul><a href=\"https://allensdk.readthedocs.io/en/latest/_static/examples/nb/ecephys_lfp_analysis.html\">https://allensdk.readthedocs.io/en/latest/_static/examples/nb/ecephys_lfp_analysis.html</a></ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
    "<b>Accessing LFP data</b>\n",
    "<br>\n",
    "We'll start by loading the LFP data from one of the probes in our session, using the `get_lfp` function.\n",
    "<br>\n",
    "We need to provide this function with a probe id, which we can pull out of the `session.probes` table. \n",
    "<br>\n",
    "(Note that the \"id\" column is the index of the dataframe, and thus must be accessed differently than other columns.)\n",
    "\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_id = session.probes.index[0]\n",
    "lfp = session.get_lfp(probe_id)\n",
    "print(lfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
    "<b>Plot the LFP data array</b>\n",
    "<br>\n",
    "To visualize this data, we'll first use the built-in xarray plotting to generate a quick plot. This is too much data to plot all at once, so we select a subset first. Just as in pandas, we use the `loc` property, but since xarray has named dimensions, we can specify our selections by name rather than by order, using a dict.\n",
    "<br>\n",
    "We'll also add the structure boundaries to this plot, as we did with unit waveforms.\n",
    "\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "lfp_plot = lfp.loc[dict(time=slice(5,20))]\n",
    "x, y = lfp_plot.time, range(len(lfp_plot.channel))\n",
    "plt.pcolormesh(x, y, lfp_plot.values.T)\n",
    "plt.colorbar(ax=ax)\n",
    "\n",
    "ax.set_xlabel(\"time (s)\")\n",
    "\n",
    "# include the structure data\n",
    "structure_acronyms, intervals = session.channel_structure_intervals(lfp.channel.values)\n",
    "ax.set_yticks(intervals)\n",
    "interval_midpoints = [ (aa + bb) / 2 for aa, bb in zip(intervals[:-1], intervals[1:])]\n",
    "ax.set_yticks(interval_midpoints, minor=True)\n",
    "ax.set_yticklabels(structure_acronyms, minor=True)\n",
    "plt.tick_params(\"y\", which=\"major\", labelleft=False, length=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Plot and filter single-channel LFP timeseries</b>\n",
    "\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by plotting the timeseries of a single channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = lfp.channel[0]\n",
    "lfp_subset = lfp.loc[dict(channel=channel, time=slice(5,20))]\n",
    "\n",
    "# you might then want to clear the full LFP from memory if not using it\n",
    "# lfp = None\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "lfp_subset.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might also want to visualize a specific frequency band by filtering. To do this we'll want to convert our data into standard numpy arrays for easier processing using the DataArray object's `values` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = lfp_subset.time.values\n",
    "v = lfp_subset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "freq_window = (4, 10)\n",
    "filt_order = 3\n",
    "fs = 1/(t[1]-t[0])\n",
    "b, a = scipy.signal.butter(filt_order, freq_window, btype='bandpass', fs=fs)\n",
    "v_alpha = scipy.signal.lfilter(b, a, v)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.plot(t, v)\n",
    "plt.plot(t, v_alpha,'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>LFP Power spectral density (PSD)</b>\n",
    "\n",
    "\n",
    "<p> Next we're going to analyze some spectral properties of this signal using the `scipy.signal` library. \"Spectral\" refers to decomposing a signal into a sum of simpler components identified by their frequencies. The set of frequencies of the components forms a *spectrum* that tells us about the complete signal. You can see a full list of spectral analysis functions in scipy here: https://docs.scipy.org/doc/scipy/reference/signal.html#spectral-analysis\n",
    "\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import the package, and inspect the `periodogram` function, which estimates the size of the different frequency components of the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "help(scipy.signal.periodogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of options that we won't go into here for refining the analysis. The one piece of information we do need is `fs`, the sampling frequency. If we used the default value `fs=1.0` our results would not match the true frequencies of the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 1/(t[1]-t[0])\n",
    "\n",
    "f, psd = scipy.signal.periodogram(v, fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll plot the power spectrum on a semilog plot, since power can vary over many orders of magnitude across frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "plt.semilogy(f,psd,'k')\n",
    "plt.xlim((0,100))\n",
    "plt.yticks(size=15)\n",
    "plt.xticks(size=15)\n",
    "plt.ylabel('Power ($uV^{2}/Hz$)',size=20)\n",
    "plt.xlabel('Frequency (Hz)',size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this representation of the power spectrum is extremely noisy. Luckily, many people have come up with solutions to this problem. Scipy includes a function for Welch's method, which averages out noise by computing many estimates of the power spectrum from overlapping windows of the data. You can find some more references for this approach in the Scipy documentation: https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.welch.html#scipy.signal.welch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, psd = scipy.signal.welch(v, fs, nperseg=1000)\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.semilogy(f,psd,'k')\n",
    "plt.xlim((0,100))\n",
    "plt.yticks(size=15)\n",
    "plt.xticks(size=15)\n",
    "plt.ylabel('Power ($uV^{2}/Hz$)',size=20)\n",
    "plt.xlabel('Frequency (Hz)',size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Calculate and plot the time-frequency profile (\"spectrogram\")</b>\n",
    "\n",
    "\n",
    "<p> We might also be interested in how the frequency content of the signal varies over time. In a neural context, power in different frequency bands is often linked to specific types of processing, so we might explore whether changes in the spectrum coincide with specific behaviors or stimuli.</p>\n",
    "<p>\n",
    "The *spectrogram* is essentially an estimate of the power spectrum computed in a sliding time window, producing a 2D representation of the signal power across frequency and time.</p>\n",
    "\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, t_spec, spec = scipy.signal.spectrogram(v, fs=fs, window='hanning',\n",
    "                            nperseg=1000, noverlap=1000-1, mode='psd')\n",
    "# Scipy assumes our signal starts at time=0, so we need to provide the offset\n",
    "t_spec = t_spec + t[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the matplotlib `pcolormesh` function to visualize this data as an image. We can pass this function x and y coordinates to get the axis labeling right. We also log-transform the power spectrum and restrict to frequencies less than 100 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmax = 80\n",
    "x, y = t_spec, f[f<fmax]\n",
    "plot_data = np.log10(spec[f<fmax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll plot the spectrum together with the raw signal in subplots. Note that we explicitly set the x-axis limits to align the plots. (Alternatively, it's possible to directly couple the limits of different subplots.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.pcolormesh(x, y, plot_data, cmap=cm.jet)\n",
    "window = [5,20]\n",
    "plt.xlim(window)\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(t, v, 'k')\n",
    "plt.xlim(window)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Voltage (a.u.)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h2> 7. Optotagging </h2>\n",
    "<p>\n",
    "At the end of each session is a period of optogenetic stimulation, when lights are shone onto the cortical surface and stimulate neurons that are Cre+.\n",
    "</p>\n",
    "<p>\n",
    "In this section, we will take a look at what data is available - for a longer treatment of using this data to classify neurons as Cre+, see the link below\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "[optotagging tutorial](https://allensdk.readthedocs.io/en/latest/_static/examples/nb/ecephys_optotagging.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Pick a new session from a transgenic mouse, and see what optotagging data is available. </b> </p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = sessions[sessions.full_genotype.str.match('Pvalb')].index[-3]\n",
    "session = cache.get_session_data(session_id)\n",
    "print(session.full_genotype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What type of information is available about optotagging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opto_stim_table = session.optogenetic_stimulation_epochs\n",
    "opto_stim_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What different types of stimuli are used, and how many times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opto_stim_table.groupby(['stimulus_name','duration','level'])['condition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
    "    <p><b>Plot spike rasters around a single optogenetic stimulus epoch </b> </p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch = opto_stim_table[(opto_stim_table.stimulus_name=='pulse')&(opto_stim_table.duration>0.006)&(opto_stim_table.level==2.0)].iloc[0]\n",
    "epoch = opto_stim_table[(opto_stim_table.stimulus_name=='raised_cosine')&(opto_stim_table.level==2.0)].iloc[0]\n",
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plot_raster(session.spike_times, epoch.start_time-0.1, epoch.stop_time+0.1)\n",
    "plt.axvspan(epoch.start_time, epoch.stop_time, color='red', alpha=0.1)\n",
    "plt.xlabel('Time (sec)', fontsize=16)\n",
    "plt.ylabel('Units', fontsize=16)\n",
    "plt.tick_params(axis=\"y\", labelleft=False, left=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
    "    <p><b>Plot rasters of only the 30 most active </b></p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_fr = session.units.sort_values(by=\"firing_rate\", ascending=False)\n",
    "spike_times_by_firing_rate = {\n",
    "    uid: session.spike_times[uid] for uid in by_fr.index.values[:30]\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plot_raster(spike_times_by_firing_rate, epoch.start_time-0.3, epoch.stop_time+0.3)\n",
    "plt.axvspan(epoch.start_time, epoch.stop_time, color='red', alpha=0.1)\n",
    "plt.xlabel('Time (sec)', fontsize=16)\n",
    "plt.ylabel('Units', fontsize=16)\n",
    "plt.tick_params(axis=\"y\", labelleft=False, left=False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:swdb_np]",
   "language": "python",
   "name": "conda-env-swdb_np-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
