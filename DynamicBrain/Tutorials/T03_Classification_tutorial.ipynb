{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../resources/cropped-SummerWorkshop_Header.png\">  \n",
    "\n",
    "<h1 align=\"center\">Classification Tutorial SWDB 2021 </h1> \n",
    "<h3 align=\"center\">Tuesday, August 31, 2021</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This tutorial covers some general concepts in classification and highlights useful functionality in the sklearn package for performing classification.\n",
    "\n",
    "Classification is closely related to regression. In the case of regression, we're trying to discover a mapping from independent continuous variables onto dependent continuous variables. In the case of classification, we're trying to discover a mapping from independent continous variables onto dependent categorical (i.e. discrete) variables. \n",
    "\n",
    "** Whereas regression attempts to find the best fit to the data, classification emphasizes finding the best boundaries to separate classes. **\n",
    "\n",
    "One prominent use case in systems neuroscience is that **decoding is typically framed as a classification problem**. For example, mapping an activity vector (cell activity x number of neurons) onto some categorical feature that we believe is represented in that population activity. The category could be which stimulus out of a set of stimuli was presented on that trial, or the behavioral state of the animal (e.g. asleep versus awake, running versus stationary, engaged versus disengaged).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import datasets\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn import neighbors\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.datasets` provides the ability to generate synthetic data that have specific kinds of structure that are useful for understanding and validating the performance of various classification algorithms.\n",
    "\n",
    "Here, we'll generate a 2D dataset with partial overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.make_classification(n_features=2,n_redundant=0,random_state=1,n_samples=1000)\n",
    "        \n",
    "print(np.shape(X))\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the shape of the training sets is X: (num_samples, num_dimensions) and y: (num_samples)\n",
    "\n",
    "This function can visualize the datasets we'll generate in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classes(X,y):\n",
    "    \n",
    "    classes = np.unique(y)\n",
    "    num_classes = len(classes)\n",
    "    \n",
    "    color = 'rbgmyk'\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    for cl in range(num_classes):\n",
    "        plt.scatter(X[y==cl,0],X[y==cl,1],c=color[cl],edgecolor='none')\n",
    "    plt.xlim(X[:,0].min(),X[:,0].max())\n",
    "    plt.ylim(X[:,1].min(),X[:,1].max())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classes(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to split our data into a *train* and *test* set to ensure that our classifier can generalize to data that it hasn't yet seen. Again sklearn provides a straightforward function to make this split. Here, I'm telling the function that I want 20% of the data held-out for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_train,X_test,y_train,y_test] = model_selection.train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first classification algorithm we'll try, and one typically worth trying first, is linear discriminant analysis. LDA will attempt to find a linear boundary between our classes.\n",
    "\n",
    "[Linear Discriminant Analysis](https://towardsdatascience.com/linear-discriminant-analysis-explained-f88be6c1e00b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LDA()\n",
    "classifier.fit(X_train,y_train)\n",
    "y_hat = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function can visualize the test data that is correctly versus incorrectly classified.\n",
    "Correctly classified data are displayed as filled circles, whereas incorrectly classified data are displayed as open circles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_performance(X,y,y_hat):\n",
    "    \n",
    "    classes = np.unique(y_test)\n",
    "    num_classes = len(classes)\n",
    "    \n",
    "    color = 'rbgmyk'\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    for cl in range(num_classes):\n",
    "        \n",
    "        is_class = y == cl\n",
    "        is_correct = y == y_hat\n",
    "        \n",
    "        plt.scatter(X[is_class & is_correct,0],X[is_class & is_correct,1],c=color[cl],edgecolor='none')\n",
    "        plt.scatter(X[is_class & ~is_correct,0],X[is_class & ~is_correct,1],c='none',edgecolor=color[cl])\n",
    "        \n",
    "    plt.xlim(X[:,0].min(),X[:,0].max())\n",
    "    plt.ylim(X[:,1].min(),X[:,1].max())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_test_performance(X_test,y_test,y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to visualize the actual decision boundary that was learned, this function will push many points on a grid through the classifier and display them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classifier_boundary(classifier,X,num_classes=2):\n",
    "\n",
    "    (grid_x1, grid_x2) = np.meshgrid(np.linspace(X[:,0].min(),X[:,0].max(),80),np.linspace(X[:,1].min(),X[:,1].max(),80))\n",
    "    grid = np.vstack([grid_x1.reshape(-1),grid_x2.reshape(-1)]).T\n",
    "    grid_classes = classifier.predict(grid)   \n",
    "    \n",
    "    plot_classes(grid,grid_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classifier_boundary(classifier,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier essentially learns to classify the data based on whether the first dimension is greater than or less than zero.\n",
    "\n",
    "The next exercise illustrates an important aspect of training classifiers: since the classifier learns both the generalizable structure of the data that we're trying to capture as well as the specific variation (noise) in the training data, **the performance of a classifier can be no better on the test data than on the training data**. Typically, it's worse. This phenomenon is called **overfitting**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "num_folds = 5\n",
    "\n",
    "X, y = datasets.make_classification(n_features=2,n_redundant=0,random_state=0,n_samples=20)\n",
    "\n",
    "scores = model_selection.cross_validate(classifier,X,y, cv=5, return_train_score=True)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "ax = plt.subplot(111)\n",
    "ax.bar([0,1],[np.mean(scores['train_score']),np.mean(scores['test_score'])],color='c')\n",
    "ax.set_xticks([0.5,1.5])\n",
    "ax.set_xticklabels(['Train','Test'],fontsize=16)\n",
    "ax.set_ylabel('Fraction Correct',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try playing with the number of samples in the dataset above. You'll notice that the gap between the performance on train and test sets gets smaller as the dataset gets larger. That happens because the sample dataset begins to look more like the full population, so large train and test set should have very similar distributions. In other words, as the training set becomes infinitely large, it becomes impossible that the test set encounters a part of the distribution that is not represented in the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's try a dataset that isn't so easily separated by a linear classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.make_moons(noise=0.2,random_state=0,n_samples=1000)\n",
    "    \n",
    "plot_classes(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_train,X_test,y_train,y_test] = model_selection.train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "classifier = LDA()\n",
    "classifier.fit(X_train,y_train)\n",
    "y_hat_lda = classifier.predict(X_test)\n",
    "\n",
    "plot_test_performance(X_test,y_test,y_hat_lda)\n",
    "plot_classifier_boundary(classifier,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a non-linear classifier. K-nearest neighbors is a very straightforward non-linear classifier that just uses the class mode of the closest data points in the training set.\n",
    "\n",
    "[K-nearest neighbors](https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = neighbors.KNeighborsClassifier()\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "y_hat_knn = classifier.predict(X_test)\n",
    "\n",
    "plot_test_performance(X_test,y_test,y_hat_knn)\n",
    "plot_classifier_boundary(classifier,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the KNN classifier depends on the number of neighbors that are considered for deciding class membership. We can determine the best value of K through **validation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_to_try = np.arange(2,250,1)\n",
    "val_performance = np.zeros(np.shape(k_to_try))\n",
    "for ki, k in enumerate(k_to_try):\n",
    "    \n",
    "    classifier = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    scores = model_selection.cross_validate(classifier,X_train,y_train, cv=3)\n",
    "    \n",
    "    val_performance[ki] = np.mean(scores['test_score'])\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(k_to_try,val_performance,'ro')\n",
    "plt.xlabel('K',fontsize=16)\n",
    "plt.ylabel('Validation Performance',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the best value of K from validation to see how well it generalizes to the hold-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_K = k_to_try[np.argmax(val_performance)]\n",
    "\n",
    "classifier = neighbors.KNeighborsClassifier(n_neighbors=best_K)\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "y_hat = classifier.predict(X_test)\n",
    " \n",
    "print(\"Best K: \" + str(best_K))\n",
    "print(\"Validation Performance: \" + str(val_performance.max()))\n",
    "print(\"Test Performance: \" + str(np.mean(y_test == y_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quantitatively compare the performance of LDA and KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = np.array([\n",
    "                          (y_test==y_hat_lda).mean(),\n",
    "                          (y_test==y_hat_knn).mean()\n",
    "                        ])\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "ax = plt.subplot(111)\n",
    "ax.bar([0,1],test_accuracy,color='c')\n",
    "ax.set_xticks([0.5,1.5])\n",
    "ax.set_xticklabels(['LDA','KNN'],fontsize=16)\n",
    "ax.set_ylabel('Fraction Correct',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more types of datasets you can make with scikit-learn, many of which are not linearly classifiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.make_circles(noise=0.1, factor=0.5, random_state=1,n_samples=1000)\n",
    "    \n",
    "plot_classes(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at a dataset with more than two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.make_blobs(n_features=2, centers=3,random_state=4,n_samples=1000)\n",
    "       \n",
    "plot_classes(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_train,X_test,y_train,y_test] = model_selection.train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "classifier = neighbors.KNeighborsClassifier()\n",
    "classifier.fit(X_train,y_train) \n",
    "y_hat = classifier.predict(X_test)\n",
    "\n",
    "plot_test_performance(X_test,y_test,y_hat) \n",
    "plot_classifier_boundary(classifier,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the red and blue classes overlap, but neither overlaps with the green class. One method commonly used to determine which classes are more difficult for a classifier to distinguish is to make a \"confusion matrix.\" This is simply a matrix comparing the actual class a datapoint belongs to the class that is predicted by the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "C = confusion_matrix(y_test,y_hat)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "ax = plt.subplot(111)\n",
    "cax = ax.imshow(C,interpolation='none',origin='lower',vmin=0,vmax=C.max())\n",
    "ax.set_xlabel('Actual Class',fontsize=16)\n",
    "ax.set_ylabel('Predicted Class',fontsize=16)\n",
    "ax.set_xticks(range(3))\n",
    "ax.set_xticklabels(['Red','Blue','Green'],fontsize=16)\n",
    "ax.set_yticks(range(3))\n",
    "ax.set_yticklabels(['Red','Blue','Green'],fontsize=16)\n",
    "plt.colorbar(cax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Side note: Classification is related to another technique called clustering. Classification is performed when you have class labels, whereas clustering is performed when you do not. The former is known as supervised learning and the latter is known as unsupervised learning.\n",
    "\n",
    "Here's an example, attempting to cluster the datapoints from the previous example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means Clustering\n",
    "\n",
    "[KMeans](https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy import stats\n",
    "\n",
    "kmeans = KMeans(n_clusters=3).fit(X)\n",
    "unsupervised_y_hat = kmeans.labels_\n",
    "\n",
    "class_0, __ = stats.mode(unsupervised_y_hat[y==0])\n",
    "class_1, __ = stats.mode(unsupervised_y_hat[y==1])\n",
    "class_2, __ = stats.mode(unsupervised_y_hat[y==2])\n",
    "\n",
    "sorted_unsup_y_hat = unsupervised_y_hat.copy()\n",
    "sorted_unsup_y_hat[unsupervised_y_hat==class_0] = 0\n",
    "sorted_unsup_y_hat[unsupervised_y_hat==class_1] = 1\n",
    "sorted_unsup_y_hat[unsupervised_y_hat==class_2] = 2\n",
    "\n",
    "plot_test_performance(X,y,sorted_unsup_y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = confusion_matrix(y,sorted_unsup_y_hat)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "ax = plt.subplot(111)\n",
    "cax = ax.imshow(C,interpolation='none',origin='lower',vmin=0,vmax=C.max())\n",
    "ax.set_xlabel('Actual Class',fontsize=16)\n",
    "ax.set_ylabel('Predicted Class',fontsize=16)\n",
    "ax.set_xticks(range(3))\n",
    "ax.set_xticklabels(['Red','Blue','Green'],fontsize=16)\n",
    "ax.set_yticks(range(3))\n",
    "ax.set_yticklabels(['Red','Blue','Green'],fontsize=16)\n",
    "plt.colorbar(cax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In general, class labels provide important information about where exactly class boundaries should be drawn. Unsupervised learning must rely on the natural breaks in the data, which might be difficult to find under noisy conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's try a decision tree classifier. Decision trees are useful because the results are easily interpreted by human beings. In the end, you get a series of choices on the values of individual features that tell you which class to assign any given datapoint to. They're called decision trees because you always start at the same point (\"the root\") and each consecutive choice leads you down a particular branch, until you arrive at a class assignment (\"the leaves\").\n",
    "\n",
    "[Decision Tree](https://towardsdatascience.com/understanding-decision-tree-classifier-7366224e033b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "classifier = DecisionTreeClassifier(random_state=0)\n",
    "classifier = classifier.fit(iris.data, iris.target)\n",
    "\n",
    "#plot first versus second dimension\n",
    "plot_classes(iris.data[:,[0,1]],iris.target)\n",
    "\n",
    "#plot third versus fourth dimension\n",
    "plot_classes(iris.data[:,[2,3]],iris.target)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "ax = plt.subplot(111)\n",
    "ax.bar(range(4),classifier.feature_importances_)\n",
    "ax.set_xticks(np.arange(4)+0.5)\n",
    "ax.set_xticklabels(iris.feature_names,fontsize=12)\n",
    "ax.set_ylabel('Feature Importance',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importance (see \"Gini Importance\") gives a sense of how heavily each feature is weighted in the decision tree. In this case, overlap of classes by petal width is only slightly smaller than overlap in petal length, but that slight difference is enough for the decision tree to prioritize using petal width before considering petal length, so their relative importance is highly rectified.\n",
    "\n",
    "Below is a visualization of the tree structure of the decision process:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tree.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE YOU NEED TO... pip install pydotplus to make this work\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(classifier, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuromatch",
   "language": "python",
   "name": "neuromatch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
